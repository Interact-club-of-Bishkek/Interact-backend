import os
import pickle
import numpy as np
import faiss
from pypdf import PdfReader
from sentence_transformers import SentenceTransformer
from groq import AsyncGroq
from dotenv import load_dotenv

load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—É—Ç–µ–π
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
# –ü—É—Ç—å –∫ PDF –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–Ω—è (telegram_bot/)
PDF_PATH = os.path.join(BASE_DIR, "rules.pdf") 
# –ü—É—Ç–∏ –∫ –∏–Ω–¥–µ–∫—Å–∞–º –≤–Ω—É—Ç—Ä–∏ —Ç–µ–∫—É—â–µ–π –ø–∞–ø–∫–∏ (ai_command/)
INDEX_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)))
INDEX_FILE = os.path.join(INDEX_DIR, "faiss_index.bin")
CHUNKS_FILE = os.path.join(INDEX_DIR, "chunks.pkl")

class AIService:
    def __init__(self):
        self.index = None
        self.chunks = []
        self.is_initialized = False
        
        # 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (HuggingFace)
        print("üì• –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ SentenceTransformer...")
        self.embedder = SentenceTransformer('all-MiniLM-L6-v2')
        
        # 2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ Groq
        api_key = os.getenv("GROQ_API_KEY")
        if not api_key:
            print("‚ùå –û–®–ò–ë–ö–ê: –ù–µ –Ω–∞–π–¥–µ–Ω GROQ_API_KEY –≤ .env —Ñ–∞–π–ª–µ!")
        
        self.client = AsyncGroq(api_key=api_key)

    async def initialize(self):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è, –∑–∞–≥—Ä—É–∂–∞—é—â–∞—è –∏–ª–∏ —Å–æ–∑–¥–∞—é—â–∞—è –±–∞–∑—É."""
        if self.is_initialized:
            return

        # 3. –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã
        if os.path.exists(INDEX_FILE) and os.path.exists(CHUNKS_FILE):
            try:
                self.index = faiss.read_index(INDEX_FILE)
                with open(CHUNKS_FILE, "rb") as f:
                    self.chunks = pickle.load(f)
                print(f"‚úÖ –ë–∞–∑–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {self.index.ntotal} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤.")
                self.is_initialized = True
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑—ã: {e}. –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è.")
                # –ï—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å, –∑–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ, –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ)
                import asyncio
                await asyncio.to_thread(self.build_index)
                self.is_initialized = True
        else:
            print("‚ö†Ô∏è –ë–∞–∑–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è.")
            # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ, –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ)
            import asyncio
            await asyncio.to_thread(self.build_index)
            self.is_initialized = True
            
    def _split_text(self, text, chunk_size=1000, overlap=200):
        """–ü—Ä–æ—Å—Ç–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞–∑–±–∏–≤–∫–∏ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞—Å—Ç–∏ —Å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º"""
        chunks = []
        start = 0
        while start < len(text):
            end = start + chunk_size
            chunk = text[start:end]
            chunks.append(chunk)
            start += chunk_size - overlap
        return chunks

    def build_index(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π —Å –Ω—É–ª—è (–°–ò–ù–•–†–û–ù–ù–û)"""
        if not os.path.exists(PDF_PATH):
            return f"‚ùå –§–∞–π–ª PDF –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏: {PDF_PATH}"

        print("üîÑ –ù–∞—á–∞–ª–æ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ PDF...")
        try:
            reader = PdfReader(PDF_PATH)
            text = ""
            for page in reader.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
            
            if not text:
                return "‚ùå PDF –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞."

            self.chunks = self._split_text(text)
            print(f"üìÑ –¢–µ–∫—Å—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(self.chunks)} —á–∞—Å—Ç–µ–π. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤...")

            embeddings = self.embedder.encode(self.chunks)
            
            dimension = embeddings.shape[1]
            self.index = faiss.IndexFlatL2(dimension)
            self.index.add(np.array(embeddings).astype('float32'))

            faiss.write_index(self.index, INDEX_FILE)
            with open(CHUNKS_FILE, "wb") as f:
                pickle.dump(self.chunks, f)

            return "–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∞."

        except Exception as e:
            return f"‚ùå –û—à–∏–±–∫–∞: {e}"

    async def get_answer(self, query: str):
        """–ü–æ–∏—Å–∫ –æ—Ç–≤–µ—Ç–∞ (–ê–°–ò–ù–•–†–û–ù–ù–û)"""
        if not self.is_initialized:
            # –ï—Å–ª–∏ –±–æ—Ç –Ω–µ –±—ã–ª –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (—Ö–æ—Ç—è main() –¥–æ–ª–∂–µ–Ω —ç—Ç–æ —Å–¥–µ–ª–∞—Ç—å), –∂–¥–µ–º
            await self.initialize()

        if not self.index or not self.chunks:
            return "‚ùå –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –Ω–µ –≥–æ—Ç–æ–≤–∞. –§–∞–π–ª rules.pdf –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –ø—É—Å—Ç."

        try:
            query_vector = self.embedder.encode([query])
            
            # –£–≤–µ–ª–∏—á–µ–Ω–æ k –¥–æ 5 –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ–≥–æ –∑–∞—Ö–≤–∞—Ç–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            D, I = self.index.search(np.array(query_vector).astype('float32'), k=5) 
            
            found_texts = [self.chunks[i] for i in I[0] if i < len(self.chunks)]
            context = "\n\n".join(found_texts)

            system_prompt = (
                "–¢—ã ‚Äî –ø–æ–ª–µ–∑–Ω—ã–π –∏ —Ç–æ—á–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç Interact Club. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. "
                "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –∏–∑–≤–ª–µ—á—å –æ—Ç–≤–µ—Ç –¢–û–õ–¨–ö–û –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –ö–û–ù–¢–ï–ö–°–¢–ê. "
                "–ï—Å–ª–∏ –≤ –ö–û–ù–¢–ï–ö–°–¢–ï –µ—Å—Ç—å —Ç–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ü–∏—Ñ—Ä—ã –∏–ª–∏ —Ñ–∞–∫—Ç—ã), —Ç—ã –û–ë–Ø–ó–ê–ù –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–µ. "
                "–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç, –æ—Ç–≤–µ—Ç—å: '–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –≤ –º–æ–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± —ç—Ç–æ–º'. "
                "–ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç—ã. "
                "\n\n--- –ö–û–ù–¢–ï–ö–°–¢ ---\n" + context
            )

            response = await self.client.chat.completions.create(
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": query}
                ],
                model="llama-3.1-8b-instant", # –ê–∫—Ç—É–∞–ª—å–Ω–æ–µ –∏–º—è –º–æ–¥–µ–ª–∏ Groq
                temperature=0.3,
            )

            return response.choices[0].message.content

        except Exception as e:
            return f"–û—à–∏–±–∫–∞ –ò–ò: {e}"

# –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞
ai_bot = AIService()